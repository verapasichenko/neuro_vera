{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Модули"
      ],
      "metadata": {
        "id": "dCis0UttIet-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t-2Ph-918WY6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.autonotebook import tqdm\n",
        "import torchvision.transforms.functional as TF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCPaqqnnDaiW"
      },
      "source": [
        "# Создание датасета"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Класс Dataset основан на классе Dataset из модуля tourch\n",
        "\n",
        "В нем мы задаем его объявление, расчёт длины и итерацию. Логика построения - объединение двух папок, каждая из которых представляет собой изображения своего класса."
      ],
      "metadata": {
        "id": "AGnN6kTIctqp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "k07ATjwka-Tg"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "  def __init__( self, papka_dir0:str, papka_dir1:str):\n",
        "    super().__init__()\n",
        "\n",
        "    self.papka_dir0 = papka_dir0\n",
        "    self.papka_dir1 = papka_dir1\n",
        "\n",
        "    self.dir0_list = sorted(os.listdir(papka_dir0))\n",
        "    self.dir1_list = sorted(os.listdir(papka_dir1))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dir0_list) + len(self.dir1_list)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    class_id = 0 if index < len(self.dir0_list) else 1\n",
        "\n",
        "    if class_id == 0:\n",
        "      image_path = os.path.join(self.papka_dir0,\n",
        "                                self.dir0_list[index])\n",
        "    else:\n",
        "      image_path = os.path.join(self.papka_dir1,\n",
        "                                self.dir1_list[index- len(self.dir0_list)])\n",
        "\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    image = TF.to_tensor(image)\n",
        "\n",
        "\n",
        "    return image, class_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YQ41BzYGa-Qs"
      },
      "outputs": [],
      "source": [
        "train = Dataset('/content/drive/MyDrive/test/bit_1',\n",
        "                '/content/drive/MyDrive/test/bit_0')\n",
        "test = Dataset('/content/drive/MyDrive/train/bit_one',\n",
        "               '/content/drive/MyDrive/train/bit_zero')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VwQfD38DggW"
      },
      "source": [
        "# Создание даталоудера"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем загрузчик датасетов, в котором задаем размеры батчей."
      ],
      "metadata": {
        "id": "yS9dGnzZdRql"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3FnjiUtpa-I6"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train, shuffle = True, batch_size = batch_size,\n",
        "    drop_last=True, num_workers=1\n",
        "    )\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test, shuffle = True, batch_size = batch_size,\n",
        "    drop_last=False, num_workers=1\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9EdA8EeDsoJ"
      },
      "source": [
        "# Архитектура сети"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Класс Block - объединение двух слоев, основанное на логике сети ResNet\n",
        "\n",
        "Класс ClassificatorNet - наша модель, состоящая из входного слоя, 5 блоков и выходного слоя."
      ],
      "metadata": {
        "id": "NVtwYd9ndhcg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ltFnZOrn8kkr"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "  def __init__(self, num_chanals):\n",
        "    super().__init__()\n",
        "\n",
        "    self.convalution0 = nn.Conv2d(num_chanals, num_chanals, 3, padding = 1)\n",
        "    self.batch_norm0 = nn.BatchNorm2d(num_chanals)\n",
        "    self.activation = nn.LeakyReLU(0.2, inplace= True)\n",
        "    self.convalution1 = nn.Conv2d(num_chanals, num_chanals, 3, padding = 1)\n",
        "    self.batch_norm1 = nn.BatchNorm2d(num_chanals)\n",
        "\n",
        "  def forward(self, x):\n",
        "    result = self.convalution0(x)\n",
        "    result = self.batch_norm0(result)\n",
        "    result = self.activation(result)\n",
        "    result = self.convalution1(result)\n",
        "    result = self.batch_norm1(result)\n",
        "\n",
        "    return self.activation(x + result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HybdW3kRAtYx"
      },
      "outputs": [],
      "source": [
        "class ClassificatorNet(nn.Module):\n",
        "  def __init__(self,in_ch, num_ch, out_ch):\n",
        "    super().__init__()\n",
        "    self.conv0 =  nn.Conv2d(in_ch, num_ch, 3, stride=2, padding= 1)\n",
        "    self.activation0 = nn.LeakyReLU(0.2, inplace= True)\n",
        "\n",
        "\n",
        "    self.layer1 = Block(num_ch)\n",
        "    self.conv1 = nn.Conv2d(num_ch, num_ch, 1, stride=1, padding=1)\n",
        "    self.layer2 = Block(num_ch)\n",
        "    self.conv2 = nn.Conv2d(num_ch, 2*num_ch, 3, stride=2, padding= 1)\n",
        "    self.layer3 = Block(num_ch*2)\n",
        "    self.conv3 = nn.Conv2d(2*num_ch, 4*num_ch, 3, stride =2 , padding =1)\n",
        "    self.layer4 = Block(num_ch*4)\n",
        "    self.conv4 = nn.Conv2d(4*num_ch, 8*num_ch, 3, stride =2 , padding =1)\n",
        "    self.layer5 = Block(num_ch*8)\n",
        "\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear = nn.Linear(8*num_ch, out_ch)\n",
        "    self.soft = nn.Softmax(1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    result = self.conv0(x)\n",
        "    result = self.activation0(result)\n",
        "\n",
        "    result = self.layer1(result)\n",
        "    result = self.conv1(result)\n",
        "    result = self.layer2(result)\n",
        "    result = self.conv2(result)\n",
        "    result = self.layer3(result)\n",
        "    result = self.conv3(result)\n",
        "    result = self.layer4(result)\n",
        "    result = self.conv4(result)\n",
        "    result = self.layer5(result)\n",
        "\n",
        "    result = self.avgpool(result)\n",
        "    result = self.flatten(result)\n",
        "    result = self.linear(result)\n",
        "\n",
        "    return self.soft(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmWe6GWyD2ta"
      },
      "source": [
        "# Оптимайзер, лосс и метрики"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создание модели. Входных слоя 3 - RGB, количество слоев 1 блока согласно схеме 64, выходных 2.\n",
        "\n",
        "Лосс - функция кросс энтропии.\n",
        "\n",
        "Оптимайзер - Адам с linear rate 10^(-4).\n",
        "\n",
        "Оптимайзер, его параметры и лосс функция выбраны согалсно статье."
      ],
      "metadata": {
        "id": "C1AeQcnpd_Ot"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "P-9lq91rYsPs"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_qX6tHxYsM2"
      },
      "outputs": [],
      "source": [
        "model = ClassificatorNet(3, 64, 2)\n",
        "\n",
        "count_parameters(model), model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OOrS88gwYsKA"
      },
      "outputs": [],
      "source": [
        "loss_funk = nn.CrossEntropyLoss()\n",
        "Optimizer = torch.optim.Adam(model.parameters(), lr= 0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wq9M9g_6Yr9h"
      },
      "outputs": [],
      "source": [
        "def metric(pred, label):\n",
        "  answer = F.softmax(pred.detach()).numpy().argmax(1) == label.numpy().argmax(1)\n",
        "  return answer.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8w-aS1_GkMr"
      },
      "source": [
        "# Тренировочный цикл"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучение из 10 эпох, на датасете 3200 изображений. Для построения графиков записываем значения лосса и точность в массивы."
      ],
      "metadata": {
        "id": "cnUeLNMBemdk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5IEYl-5HEuP"
      },
      "outputs": [],
      "source": [
        "epochs =  8\n",
        "loss_epochs_list = []\n",
        "acc_epochs_list = []\n",
        "for epoch in range(epochs):\n",
        "  loss_val = 0\n",
        "  metr_val = 0\n",
        "\n",
        "  for sample in (pbar := tqdm(train_loader)):\n",
        "    img, label = sample[0], sample[1]\n",
        "    Optimizer.zero_grad()\n",
        "\n",
        "    label = F.one_hot(label, 2).float()\n",
        "    pred = model(img)\n",
        "\n",
        "    loss = loss_funk(pred, label)\n",
        "\n",
        "    loss.backward()\n",
        "    loss_item = loss.item()\n",
        "    loss_val +=loss_item\n",
        "\n",
        "    Optimizer.step()\n",
        "    metr_current = metric(pred,label)\n",
        "    metr_val += metr_current\n",
        "  pbar.set_description(f'loss: {loss_item:.5f}, metric: {metr_current:.5f}')\n",
        "  loss_epochs_list += [loss_val/len(train_loader)]\n",
        "  acc_epochs_list += [metr_val/len(train_loader)]\n",
        "  print(loss_epochs_list[-1])\n",
        "  print(acc_epochs_list[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daeA0gjPVAC4"
      },
      "outputs": [],
      "source": [
        "plt.title('Loss:')\n",
        "plt.plot(loss_epochs_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyI4ykUSVn8A"
      },
      "outputs": [],
      "source": [
        "plt.title('Accuracy: ')\n",
        "plt.plot(acc_epochs_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6weQZFzxpAmu"
      },
      "source": [
        "# Тесты"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тесты на выборке из 800 изображений. Модель на данном этапе не обучается."
      ],
      "metadata": {
        "id": "FUckTtisfKig"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQnSTm3fKq_6"
      },
      "outputs": [],
      "source": [
        "loss_val = 0\n",
        "metr_val = 0\n",
        "\n",
        "for sample in (pbar := tqdm(test_loader)):\n",
        "  img, label = sample[0], sample[1]\n",
        "\n",
        "  label = F.one_hot(label, 2).float()\n",
        "  pred = model(img)\n",
        "  loss = loss_funk(pred, label)\n",
        "  loss_item = loss.item()\n",
        "  loss_val +=loss_item\n",
        "\n",
        "  metr_current = metric(pred,label)\n",
        "  metr_val += metr_current\n",
        "pbar.set_description(f'loss: {loss_item:.5f}, metric: {metr_current:.5f}')\n",
        "print(loss_val/len(test_loader))\n",
        "print(metr_val/len(test_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сохранение весов модели."
      ],
      "metadata": {
        "id": "mlOOvOrZfQ_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/Model.pth')"
      ],
      "metadata": {
        "id": "Srl04_IJTDbV"
      },
      "execution_count": 19,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}